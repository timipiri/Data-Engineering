!pip install html5lib
!pip install requests
!pip install bs4
!pip install pandas
!pip install sqlite3
!pip install numpy
!pip install datetime

import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import sqlite3
from datetime import datetime
import csv
data_url = 'https://web.archive.org/web/20230908091635 /https://en.wikipedia.org/wiki/List_of_largest_banks'
exchange_rate_path = "exchange_rate.csv"
table_attribs = ["Name", "MC_USD_Billion"]
db_name = 'Banks.db'
table_name = 'Largest_banks'
output_csv_path = './Largest_banks_data.csv'
log_file = "code_log.txt"

# Define functions for ETL operations
def log_progress(message):
    ''' This function logs the mentioned message of a given stage of the
    code execution to a log file. Function returns nothing'''
    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second 
    now = datetime.now() # get current timestamp 
    timestamp = now.strftime(timestamp_format) 
    with open('code_log.txt',"a") as f: 
        f.write(timestamp + ' : ' + message + '\n')

# Task2: Extracting data
def extract(url, table_attribs):
    ''' This function aims to extract the required
    information from the website and save it to a data frame. The
    function returns the data frame for further processing. '''
    page = requests.get(url).text
    print(page[1399:1423])
    soup = BeautifulSoup(page,'html.parser')
    df = pd.DataFrame(columns=table_attribs)
    tables = soup.find_all('tbody')
    rows = tables[0].find_all('tr')

    for row in rows:
        if row.find('td') is not None:
           col = row.find_all('td')
           bank_name = col[1].find_all('a')[1]['title']
           market_cap = col[2].contents[0][:-1]
           data_dict = {"Name": bank_name,
                             "MC_USD_Billion": float(market_cap)}
           df1 = pd.DataFrame(data_dict, index=[0])
           df = pd.concat([df,df1], ignore_index=True)
    return df

# Read CSV File
def read_exchange_rate_csv(file_path):
    exchange_rate_dict = {}
    with open(file_path, 'r') as file:
        reader = csv.reader(file)
        for row in reader:
            # Assuming the first column contains the keys and the second column contains the values
            if len(row) >= 2:  # Check if the row has at least two columns
                exchange_rate_dict[row[0]] = row[1]
    return exchange_rate_dict
exchange_rate_file_path = "/home/project/exchange_rate.csv"
exchange_rate_dict = read_exchange_rate_csv(exchange_rate_file_path)
print(exchange_rate_dict)

# Transform data
def transform(df, csv_path):
    ''' This function accesses the CSV file for exchange rate
    information, and adds three columns to the data frame, each
    containing the transformed version of Market Cap column to
    respective currencies'''    
    exchange_rate = pd.read_csv(csv_path)
    exchange_rate = exchange_rate.set_index('Currency').to_dict()['Rate']
    df['MC_GBP_Billion'] = [np.round(x*exchange_rate['GBP'],2) for x in df['MC_USD_Billion']]
    df['MC_EUR_Billion'] = [np.round(x*exchange_rate['EUR'],2) for x in df['MC_USD_Billion']]
    df['MC_INR_Billion'] = [np.round(x*exchange_rate['INR'],2) for x in df['MC_USD_Billion']]
    return df

# Load to CSV
def load_to_csv(df, output_path):
    ''' This function saves the final data frame as a CSV file in
    the provided path. Function returns nothing.'''
    df.to_csv(output_path)

# Load to database
def load_to_db(df, sql_connection, table_name):
    ''' This function saves the final data frame to a database
    table with the provided name. Function returns nothing.'''
    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)

def run_query(query_statement, sql_connection):
    ''' This function runs the query on the database table and
    prints the output on the terminal. Function returns nothing. '''
    print(query_statement)
    query_output = pd.read_sql(query_statement, sql_connection)
    print(query_output)

# Actual code
log_progress('Preliminaries complete. Initiating ETL process')
url = 'https://web.archive.org/web/20230908091635 /https://en.wikipedia.org/wiki/List_of_largest_banks'
table_attribs = ["Name", "MC_USD_Billion"]
df = extract(url, table_attribs)

log_progress('Data extraction complete. Initiating Transformation process')
exchange_rate_csv_path = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv"
df = transform(df, exchange_rate_csv_path)

log_progress('Data transformation complete. Initiating Loading process')
output_csv_path = './Largest_banks_data.csv'
load_to_csv(df, output_csv_path)

log_progress('Data saved to CSV file')

db_name = 'Banks.db'
table_name = 'Largest_banks'
sql_connection = sqlite3.connect(db_name)

log_progress('SQL Connection initiated.')

load_to_db(df, sql_connection, table_name)

log_progress('Data loaded to Database as table. Executing queries')

queries = [
    "SELECT * FROM Largest_banks",
    "SELECT AVG(MC_GBP_Billion) FROM Largest_banks",
    "SELECT Name from Largest_banks LIMIT 5"
]

for i, query in enumerate(queries):
    run_query(query, sql_connection)

log_progress('Process Complete.')
sql_connection.close()
