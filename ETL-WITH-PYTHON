import requests
import pandas as pd
from bs4 import BeautifulSoup
import sqlite3
import numpy as np
from datetime import datetime

# Task 1: Write a function to log progress
def log_progress(log_points):
    try:
        with open('code_log.txt', 'a') as f:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            for point in log_points:
                f.write(f"{timestamp} - {point}\n")
    except Exception as e:
        print(f"Error occurred while logging progress: {str(e)}")

# Task 2: Extract tabular information from the given URL
def extract(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')
        table = soup.find('table', {'class': 'wikitable'})

        # Extract data from the table
        df = pd.read_html(str(table))[0]
        df.columns = df.iloc[0]
        df = df[1:].reset_index(drop=True)

        return df
    except Exception as e:
        print(f"Error occurred while extracting data from URL: {str(e)}")
        return None

# Task 3: Transform dataframe by adding columns for Market Capitalization in GBP, EUR and INR
def transform(df, exchange_rates_df):
    try:
        # Merge dataframes on Currency column
        df['MC_USD_Billion'] = pd.to_numeric(df['Market capitalization in billion USD (2017)'])
        df_merged = df.merge(exchange_rates_df, on='Currency')

        # Convert market capitalization to GBP, EUR, and INR
        df_merged['MC_GBP_Billion'] = df_merged['MC_USD_Billion'] * df_merged['GBP']
        df_merged['MC_EUR_Billion'] = df_merged['MC_USD_Billion'] * df_merged['EUR']
        df_merged['MC_INR_Billion'] = df_merged['MC_USD_Billion'] * df_merged['INR']

        # Round values to 2 decimal places
        df_merged = df_merged.round({'MC_GBP_Billion': 2, 'MC_EUR_Billion': 2, 'MC_INR_Billion': 2})

        return df_merged
    except Exception as e:
        print(f"Error occurred during transformation: {str(e)}")
        return None

# Task 4: Load transformed dataframe to an output CSV file
def load_to_csv(df, output_csv_path):
    try:
        df.to_csv(output_csv_path, index=False)
        print("Data saved to CSV successfully.")
    except Exception as e:
        print(f"Error occurred while saving data to CSV: {str(e)}")

# Task 5: Load transformed dataframe to an SQL database server as a table
def load_to_db(df, db_name, table_name):
    try:
        conn = sqlite3.connect(db_name)
        df.to_sql(table_name, conn, if_exists='replace', index=False)
        conn.close()
        print("Data loaded to database successfully.")
    except Exception as e:
        print(f"Error occurred while loading data to database: {str(e)}")

# Task 6: Run queries on the database table
def run_queries(db_name, queries):
    try:
        conn = sqlite3.connect(db_name)
        for query in queries:
            result = conn.execute(query)
            print(f"Query: {query}")
            for row in result:
                print(row)
        conn.close()
    except Exception as e:
        print(f"Error occurred while running queries: {str(e)}")

# Task 7: Verify log entries
def verify_log():
    try:
        with open('code_log.txt', 'r') as f:
            content = f.read()
            print("Log entries:")
            print(content)
    except Exception as e:
        print(f"Error occurred while verifying log entries: {str(e)}")

# Main function
def main():
    try:
        # Task 1: Log progress
        log_points = ["Task 1: Log progress", "Task 2: Extracting data from URL", "Task 3: Transforming data",
                      "Task 4: Loading data to CSV", "Task 5: Loading data to database", "Task 6: Running queries",
                      "Task 7: Verifying log entries"]
        log_progress(log_points)

        # Task 2: Extract tabular information from URL
        url = "https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks"
        df = extract(url)

        # Task 3: Transform dataframe
        exchange_rates_url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv"
        exchange_rates_df = pd.read_csv(exchange_rates_url)
        transformed_df = transform(df, exchange_rates_df)

        # Task 4: Load transformed dataframe to CSV
        output_csv_path = "./Largest_banks_data.csv"
        load_to_csv(transformed_df, output_csv_path)

        # Task 5: Load transformed dataframe to database
        db_name = "Banks.db"
        table_name = "Largest_banks"
        load_to_db(transformed_df, db_name, table_name)

        # Task 6: Run queries on the database table
        queries = ["SELECT * FROM Largest_banks LIMIT 5;"]
        run_queries(db_name, queries)

        # Task 7: Verify log entries
        verify_log()
    except Exception as e:
        print(f"Error occurred: {str(e)}")

if __name__ == "__main__":
    main()
